#!/usr/bin/env python3
"""
Script para mostrar estadÃ­sticas de entrenamiento en terminal
"""
import pandas as pd
import os
from pathlib import Path

def analyze_training_results(results_dir):
    """
    Analiza los resultados de entrenamiento y muestra estadÃ­sticas
    """
    results_dir = Path(results_dir)
    
    # Verificar que el directorio existe
    if not results_dir.exists():
        print(f"âŒ Directorio no encontrado: {results_dir}")
        return
    
    # Cargar mÃ©tricas
    csv_path = results_dir / "training_metrics.csv"
    if not csv_path.exists():
        print(f"âŒ Archivo de mÃ©tricas no encontrado: {csv_path}")
        return
    
    df = pd.read_csv(csv_path)
    
    print("="*80)
    print(f"ğŸ“Š ANÃLISIS DE RESULTADOS: {results_dir.name}")
    print("="*80)
    
    # InformaciÃ³n bÃ¡sica
    print(f"ğŸ“ˆ InformaciÃ³n bÃ¡sica:")
    print(f"   ğŸ”„ Ã‰pocas completadas: {len(df)}")
    print(f"   ğŸ“ Directorio: {results_dir}")
    print(f"   ğŸ“‹ Archivo mÃ©tricas: {csv_path}")
    
    # EstadÃ­sticas de Loss
    print(f"\nğŸ“‰ EstadÃ­sticas de Loss:")
    print(f"   ğŸš‚ Train Loss:")
    print(f"      Inicial: {df['train_loss'].iloc[0]:.6f}")
    print(f"      Final:   {df['train_loss'].iloc[-1]:.6f}")
    print(f"      Mejor:   {df['train_loss'].min():.6f} (Ã©poca {df['train_loss'].idxmin() + 1})")
    print(f"      Mejora:  {((df['train_loss'].iloc[0] - df['train_loss'].iloc[-1]) / df['train_loss'].iloc[0] * 100):.1f}%")
    
    print(f"   ğŸ” Validation Loss:")
    print(f"      Inicial: {df['val_loss'].iloc[0]:.6f}")
    print(f"      Final:   {df['val_loss'].iloc[-1]:.6f}")
    print(f"      Mejor:   {df['val_loss'].min():.6f} (Ã©poca {df['val_loss'].idxmin() + 1})")
    print(f"      Mejora:  {((df['val_loss'].iloc[0] - df['val_loss'].iloc[-1]) / df['val_loss'].iloc[0] * 100):.1f}%")
    
    # EstadÃ­sticas de Dice Score
    print(f"\nğŸ¯ EstadÃ­sticas de Dice Score:")
    print(f"   ğŸš‚ Train Dice:")
    print(f"      Inicial: {df['train_dice'].iloc[0]:.6f}")
    print(f"      Final:   {df['train_dice'].iloc[-1]:.6f}")
    print(f"      Mejor:   {df['train_dice'].max():.6f} (Ã©poca {df['train_dice'].idxmax() + 1})")
    print(f"      Mejora:  {((df['train_dice'].iloc[-1] - df['train_dice'].iloc[0]) / (df['train_dice'].iloc[0] + 1e-8) * 100):.1f}%")
    
    print(f"   ğŸ” Validation Dice:")
    print(f"      Inicial: {df['val_dice'].iloc[0]:.6f}")
    print(f"      Final:   {df['val_dice'].iloc[-1]:.6f}")
    print(f"      Mejor:   {df['val_dice'].max():.6f} (Ã©poca {df['val_dice'].idxmax() + 1})")
    print(f"      Mejora:  {((df['val_dice'].iloc[-1] - df['val_dice'].iloc[0]) / (df['val_dice'].iloc[0] + 1e-8) * 100):.1f}%")
    
    # Tabla de progreso por Ã©poca
    print(f"\nğŸ“Š Progreso por Ã©poca:")
    print(f"{'Ã‰poca':<6} {'Train Loss':<12} {'Val Loss':<12} {'Train Dice':<12} {'Val Dice':<12}")
    print("-" * 60)
    for _, row in df.iterrows():
        print(f"{int(row['epoch']):<6} {row['train_loss']:<12.6f} {row['val_loss']:<12.6f} {row['train_dice']:<12.6f} {row['val_dice']:<12.6f}")
    
    # AnÃ¡lisis de tendencias
    print(f"\nğŸ” AnÃ¡lisis de tendencias:")
    
    # Ãšltimas 3 Ã©pocas
    if len(df) >= 3:
        recent_df = df.tail(3)
        
        val_dice_trend = "â¬†ï¸ creciente" if recent_df['val_dice'].is_monotonic_increasing else \
                        "â¬‡ï¸ decreciente" if recent_df['val_dice'].is_monotonic_decreasing else \
                        "â¡ï¸ estable"
        
        train_dice_trend = "â¬†ï¸ creciente" if recent_df['train_dice'].is_monotonic_increasing else \
                          "â¬‡ï¸ decreciente" if recent_df['train_dice'].is_monotonic_decreasing else \
                          "â¡ï¸ estable"
        
        print(f"   ğŸ“ˆ Ãšltimas 3 Ã©pocas:")
        print(f"      Val Dice: {val_dice_trend}")
        print(f"      Train Dice: {train_dice_trend}")
        
        # DetecciÃ³n de overfitting
        if recent_df['val_dice'].is_monotonic_decreasing and recent_df['train_dice'].is_monotonic_increasing:
            print(f"   âš ï¸  POSIBLE OVERFITTING detectado")
        elif recent_df['val_dice'].is_monotonic_increasing:
            print(f"   âœ… Modelo mejorando consistentemente")
        else:
            print(f"   â„¹ï¸  Entrenamiento estable")
    
    # Gap entre train y validation
    final_loss_gap = df['train_loss'].iloc[-1] - df['val_loss'].iloc[-1]
    final_dice_gap = df['val_dice'].iloc[-1] - df['train_dice'].iloc[-1]
    
    print(f"\nâš–ï¸  Gap Train-Validation (final):")
    print(f"   Loss gap: {final_loss_gap:.6f} {'(âš ï¸ train > val)' if final_loss_gap > 0 else '(âœ… val >= train)'}")
    print(f"   Dice gap: {final_dice_gap:.6f} {'(âœ… val > train)' if final_dice_gap > 0 else '(âš ï¸ train >= val)'}")
    
    # Recomendaciones
    print(f"\nğŸ’¡ Recomendaciones:")
    
    best_epoch = df['val_dice'].idxmax() + 1
    if best_epoch < len(df):
        print(f"   ğŸ“ El mejor modelo fue en Ã©poca {best_epoch}, no al final")
        print(f"   ğŸ’¾ Usar el modelo guardado de Ã©poca {best_epoch}")
    else:
        print(f"   âœ… El mejor modelo es el final")
    
    if df['val_dice'].max() < 0.1:
        print(f"   ğŸ“ˆ Dice score bajo (<0.1), considerar:")
        print(f"      - MÃ¡s Ã©pocas de entrenamiento")
        print(f"      - Ajustar learning rate")
        print(f"      - Verificar calidad de datos")
        print(f"      - Probar diferentes arquitecturas")
    
    if len(df) < 10:
        print(f"   ğŸ”„ Pocas Ã©pocas ({len(df)}), considerar entrenar mÃ¡s tiempo")
    
    # Archivos disponibles
    print(f"\nğŸ“ Archivos disponibles:")
    for file_path in results_dir.glob("*"):
        if file_path.is_file():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"   ğŸ“„ {file_path.name}: {size_mb:.1f} MB")
    
    plots_dir = results_dir / "plots"
    if plots_dir.exists():
        print(f"   ğŸ“Š Plots en plots/:")
        for plot_path in plots_dir.glob("*.png"):
            print(f"      ğŸ–¼ï¸  {plot_path.name}")
    
    print("="*80)

def compare_experiments(experiments_dir):
    """
    Compara mÃºltiples experimentos y muestra ranking
    """
    experiments_dir = Path(experiments_dir)
    experiment_dirs = [d for d in experiments_dir.iterdir() if d.is_dir()]
    
    if not experiment_dirs:
        print(f"âŒ No se encontraron experimentos en: {experiments_dir}")
        return
    
    print("="*80)
    print(f"ğŸ† COMPARACIÃ“N DE EXPERIMENTOS")
    print("="*80)
    
    experiments_data = []
    
    for exp_dir in experiment_dirs:
        csv_path = exp_dir / "training_metrics.csv"
        if csv_path.exists():
            df = pd.read_csv(csv_path)
            
            experiments_data.append({
                'Experimento': exp_dir.name,
                'Ã‰pocas': len(df),
                'Mejor Dice': df['val_dice'].max(),
                'Ã‰poca Mejor': df['val_dice'].idxmax() + 1,
                'Dice Final': df['val_dice'].iloc[-1],
                'Loss Final (Train)': df['train_loss'].iloc[-1],
                'Loss Final (Val)': df['val_loss'].iloc[-1],
                'Mejora Dice': ((df['val_dice'].iloc[-1] - df['val_dice'].iloc[0]) / (df['val_dice'].iloc[0] + 1e-8) * 100)
            })
    
    if experiments_data:
        # Ordenar por mejor dice score
        experiments_data.sort(key=lambda x: x['Mejor Dice'], reverse=True)
        
        print(f"ğŸ“Š Resumen de {len(experiments_data)} experimentos:")
        print()
        
        # Header
        print(f"{'Rank':<4} {'Experimento':<20} {'Mejor Dice':<12} {'Ã‰poca':<6} {'Dice Final':<12} {'Ã‰pocas':<6}")
        print("-" * 70)
        
        # Data
        for i, exp in enumerate(experiments_data, 1):
            print(f"{i:<4} {exp['Experimento']:<20} {exp['Mejor Dice']:<12.6f} {exp['Ã‰poca Mejor']:<6} {exp['Dice Final']:<12.6f} {exp['Ã‰pocas']:<6}")
        
        print()
        print(f"ğŸ¥‡ Mejor experimento: {experiments_data[0]['Experimento']}")
        print(f"   ğŸ“ˆ Mejor Dice: {experiments_data[0]['Mejor Dice']:.6f}")
        print(f"   ğŸ“ Ã‰poca: {experiments_data[0]['Ã‰poca Mejor']}")
    
    print("="*80)

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--compare":
            compare_experiments(Path("outputs"))
        else:
            analyze_training_results(sys.argv[1])
    else:
        analyze_training_results("outputs/simple_testing")
